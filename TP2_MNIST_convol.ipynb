{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning avec les modules Python tensorflow2/keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les concepts de base du *Machine Learning* (ML) peuvent être consultés si besoin dans le notebook du TP1 :  `TP1_MNIST_dense.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement / exploitation d'un réseau de neurones convolutionnel pour la reconnaissance de chiffres manuscrits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif du TP2 est de comprendre le fonctionnement d'un réseau de neurones convolutionnel et de mettre en oeuvre sa construction à l'aide du module **keras**, utilisé comme interface *high level* du module **tensorflow**. <br />\n",
    "\n",
    "Le séquencement reste le même que celui du TP1 :\n",
    "- Rappels sur le fonctionnement des réseaux convolutionels\n",
    "- Chargement des images depuis la banque MNIST.<br>\n",
    "Dans ce TP les images ne sont pas applaties en vecteurs car un réseau convolutionnel permet de garder la strcuture 2D des images.\n",
    "- Construction du modèle avec *keras*.\n",
    "- *one-hot encoding* des labels des images pour les rendre compatibles avec les sorties du réseau de neurones.\n",
    "- Entraînement & analyse des résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/ Les Réseaux de Neurones Convolutionnels (RNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principes généraux\n",
    "\n",
    "Les Réseaux de Neurones Convolutionnels (RNC, en anglais *CNN* :*Convolutionnal Neural Network*) proposent des structures particulièrement efficaces pour l'analyse du contenu des images. Pour cela les RNC mettent en oeuvre des traitements et une architecture et bien spécifiques :\n",
    "- l'extraction des caractéristiques des images (*features*) à l'aide de filtres convolutifs,\n",
    "- la réduction de la quantité d'information générée par la convolution avec des filtres de *pooling*,\n",
    "- une architecture qui empile des couches \"convolution > activation > pooling...\" chargées d'extraire les caractéristiques de l'image (*features*) qui sont au final applaties et envoyées en entrée d'un réseau dense chargé de l'étape de classification.\n",
    "\n",
    "Dans la suite du TP, nous construirons un RNC inspiré du réseau `LeNet5`, un des premiers RNC proposé par Yann LeCun *et al.* dans les années 90 pour la reconnaisannce des images MNIST :\n",
    "\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/LeNet5.png\" ><br>\n",
    "    [Lecun, Y.; Bottou, L.; Bengio, Y.; Haffner, P. (1998). \"Gradient-based learning applied to document recognition\". Proceedings of the IEEE. 86 (11): 2278–2324. doi:10.1109/5.726791.]\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des caractéristiques d'une image avec un filtre de convolution\n",
    "\n",
    "La convolution d'une image par un filtre (aussi appelé noyau, *kernel*) revient à déplacer une _petite fenêtre 2D_ ( 3x3, 5x5 ....) sur l'image et à calculer à chaque fois le produit tensoriel contracté entre les élements du filtre et les pixels de l'image délimités par le filtre (somme des produits terme à terme).<br>\n",
    "\n",
    "L'animation ci-dessous illustre la convolution d'une image 5x5 par un filtre 3x3 sans *padding* sur les bords : on obtient une nouvelle image plus petite de 3x3 pixels<br>\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/filter_3x3.png\" width=\"80\" style=\"display:inline-block;\">\n",
    "    <img src=\"img/Convolution_schematic.gif\" width=\"300\" style=\"display:inline-block;\"><br>\n",
    "    [crédit image : <a href=\"http://deeplearning.stanford.edu/tutorial\">Stanford deep learning tutorial</A>]\n",
    "</p>\n",
    "\n",
    "Pour conserver la taille de l'image d'entrée, on peut faire appel à une technique de *padding* pour créer de nouvelles données sur les bords de l'image (par dupplication des données sur les bords, ou ajout de lignes et colonnes de 0... par exemple) : \n",
    "\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/padding.gif\" width=\"350\"><br>\n",
    "    [crédit image : <a href=\"https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\"> Arden Dertat</a> ]\n",
    "</p>\n",
    "\n",
    "Le but de la convolution est d'extraire des caractéristiques particulières présentes dans l'image source : on parle de \"carte des caratéristiques\" (*feature map*) pour désigner l'image produite par l'opération de convolution. L'état de l'art conduit à utiliser plusieurs filtres convolutifs pour extraire des caractéristiques différentes : on peut avoir jusqu'à plusieurs dizaines de filtres convolutifs dans un même couche du réseau qui génèrent autant de _feature map_, d'où l'augmentation des données crées par ces opérations de convolution...\n",
    "\n",
    "#### Exemples d'extraction de caractéristiques avec des filtres convolutifs connus (filtre de [Prewitt](https://fr.wikipedia.org/wiki/Filtre_de_Prewitt)):\n",
    "\n",
    "À titre d'exemple, la figure ci-dessous montre les *features maps* obtenues en convoluant une image MNIST (un chiffre 7) avec 4 filtres 3x3 connus en traitement d'image (filtres de Prewitt pour l'extraction de contours):\n",
    "\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/7_mnist_4_filtres.png\" width=\"500\"><br>\n",
    "    [crédit image : JLC]\n",
    "</p>\n",
    "\n",
    "On voit que ces filtres agissent comme des filtres de détection de contour : dans les images de sortie, les pixels les plus blancs constituent ce que les filtres ont détecté :\n",
    "- les filtre (a) et (c) détectent des contours horizontaux inférieurs et supérieurs,\n",
    "- les filtre (b) et (d) détectent des contours verticaux droite et gauche.\n",
    "\n",
    "Ces exemples très simples permettent de comprendre comment fonctionne l'extraction des *features* d'une image par filtrage convolutif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cas général : images RGB traitée par plusieurs filtres de convolution\n",
    "\n",
    "Dans le cas général où les images correpondent à des tableaux 3D (la troisième dimension étant pour les 3 couleurs R(ed), G(reeen) &  B(lue)), le filtre de convolution est lui aussi un tableau 3D. L'opération reste identique au cas 1D : pour une position du filtre 3D sur l'image, le produit tensoriel contracté du filtre avec le sous-tableau 3D correspondant dans l'image fournit un nombre scalaire, et le balayage du procédé sur toute l'image donne la matrice des caractéristiques (*feature map*) de l'image. \n",
    "\n",
    "Par exemple si l'on utilise 10 filtres de convolution 5x5 (10 tableaux de dimensions (5,5,3)) pour traiter (avec  _padding_) une image RGB de 32x32 pixels (tableau de dimensions (32,32,3), on obtient une *feature maps*  de dimensions (32,32,10), soit 10240 termes alors que l'image source n'en a que 1024 !\n",
    "\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/conv_3D_10.png\" width=\"350\"><br>\n",
    "    [crédit image : <a href=\"https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\"> Arden Dertat</a> ]\n",
    "</p>\n",
    "\n",
    "$\\leadsto$ Pour réduire la quantité d'information générée par les filtres de convolution sans perdre trop d'information, la convolution est toujours suivie d'une opération de *pooling*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Du filtre convolutif à la couche de neurones convolutifs\n",
    "\n",
    "L'intégration du filtrage convolutif dans la structure du réseau de neurones donne l'organisation des calculs  suivante :\n",
    "\n",
    "- Chaque filtre convolutif posssède les mêmes coefficients pour les 3 couleurs : pour le réseau LeNet5 par exemple, chacun des 6 filtres 5x5x3 de la première couche possède seulement 25 coefficients, identiques pour les couleurs R, G & B.\n",
    "\n",
    "- Chaque unité (neurone convolutif) d'une *feature map* de la couche C1 reçoit 75 pixels (25 pixels rouges $R_i$, 25 pixels vert $G_i$ et 25 pixels bleus $B_i$) délimités par la position du filtre convolutif dans l'image source.\n",
    "\n",
    "- Le neurone $k$ d'une *feature map* calcule une sortie $y_k = F_a(\\sum_{i=1}^{25}{\\omega_i(R_i + G_i + B_i) - b_k})$, où $b_k$ est le biais du neurone $k$ et $F_a$ la fonction d'activation (très souvent `relu`).\n",
    "\n",
    "- pour les 6 filtres convolutrifs de la couche C1, on a donc  6 x (25 + 1) paramètres, soit 156 paramètres inconnues pour cette couche qui seront déterminé par entraînement du réseau.\n",
    "\n",
    "Le même schéma est utilisé dans toutes les couches convoltionnelles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le *pooling*\n",
    "\n",
    "Le *pooling* vise à réduire quantité de données à traiter. Comme pour l'opération de convolution, on déplace un filtre sur les éléments du tableau *feature map*  et à chaque position du filtre sur le tableau, on calcule un nombre représentant tous les éléments sélectionnés dans le filtre (par exemple la valeur maximale, ou la moyenne....). Mais contrairement à la convolution, on déplace le filtre sans recouvrement.<br>\n",
    "Dans l'exemple simplifié ci-dessous, le filtre *max spool* transforme la matrice 8x8 en une matrice 4x4 qui décrit \"à peu près\" la même information mais avec moins de données :\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/max_pool_2x2.png\" width=\"350\"><br>\n",
    "    [crédit image : JLC</a> ]\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C/ Travail à faire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<span style=\"color:brown;font-family:arial;font-size:normal\"> \n",
    "L'état de l'art actuel des projets de machine learning sous Python préconise l'utilisation d'un <span style=\"font-weight:bold;\">environnement virtuel Python</span> qui permet de maîtriser pour chaque projet les versions de l'interpréteur et des modules Python \"sensibles\" (comme tensorflow par exemple).\n",
    "\n",
    "Dans le cas d'un démarrage de l'ordinateur avec une clef USB Ubuntu, on peut considérer que la clef fournit un environnement Python dédié, à condition de ne pas faire de mises à jour des paquets Python avec <span style=\"font-style:italic\">pip install...</span>\n",
    "    \n",
    "Dans le cas contraire, la <A href=\"https://learn.ros4.pro/fr/faq/Python/\">FAQ Python</A> explique comment créer et utiliser un EVP basé sur **miniconda3** pour utiliser numpy et tensorflow2 avec la bibliothèque optimisée <A href=\"https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/onemkl.html\">MKL</A>.\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules Python tensorflow/keras\n",
    "\n",
    "Le module **keras** qui permet une manipulation de haut niveau des objets **tensorflow** est intégré dans le module **tensorflow** (tf) depuis la version 2. <br>\n",
    "La documentation du module **tf.keras** à consulter pour ce TP est ici : https://www.tensorflow.org/api_docs/python/tf/keras. \n",
    "\n",
    "Versions des modules Python validées pour ce TP sous Ubuntu 20 / Python3.8.5 :\n",
    "- tensorflow 2.4.0 incluant tensorflow.keras 2.4.0\n",
    "- OpenCV >= 4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys, cv2\n",
    "print(f\"Python    : {sys.version.split()[0]}\")\n",
    "print(f\"tensorflow: {tf.__version__} incluant keras {keras.__version__}\")\n",
    "print(f\"OpenCV    : {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incrustation des tracés matplotlib dans le cahier IPython et import de modules utiles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affectation des graines (*seed*) des générateurs pseudo-aléatoires :\n",
    "\n",
    "Le TP1 donne plus de détails sur la reproductibilité des générateurs pseudo-aléatoires utilisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)      \n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Récupération et mise en forme des données MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulter la documentation de la fonction `load_data` sur la page [tf.keras.datasets.mnist.load_data](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data) puis compléter la cellule ci-dessous pour charger les données du MNIST en nommant les données renvoyées :<br>\n",
    "- `im_train`, `im_test` pour les images d'entraînement et de test,\n",
    "- `lab_train`, `lab_test` pour les labels des images d'entraînement et de test.\n",
    "\n",
    "(En cas de message d'erreur de type _\"SSL error....\"_ pour téléchager les données du MNIST, voir [Python SSL Certification Problems in Tensorflow](https://stackoverflow.com/questions/46858630/python-ssl-certification-problems-in-tensorflow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule ci-dessous affiche les attributs `shape` et `dtype` des tableaux numpy obtenus : les valeurs son-elles cohérentes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"im_train -> shape:\", im_train.shape, \", dtype:\", im_train.dtype,)\n",
    "print(\"im_test  -> shape:\", im_test.shape,  \", dtype:\", im_test.dtype,)\n",
    "print(\"lab_train-> shape:\", lab_train.shape,  \", dtype:\", lab_train.dtype)\n",
    "print(\"lab_test -> shape:\", lab_test.shape,  \", dtype:\", lab_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme des données d'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les couches convolutionnelles du module keras attendent par défaut des tableaux multidimentionnels de la forme `(batch_size, height, width, depth)` :\n",
    "- `batch_size` : nombre d'image en entrée,\n",
    "- `height` et `width` : hauteur et largeur des images (en pixels),\n",
    "- `depth` : profondeur des tableaux (`3` pour une image RGB, `1` pour une image en ton de gris).\n",
    "\n",
    "La forme des images MNIST est :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_train.shape, im_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut donc rajouter une dimension (égale à `1`) après la troisième dimension `28`, par exemple avec la méthode `reshape` des tableaux `ndarray` de numpy.\n",
    "\n",
    "Compléter la cellule suivante pour définir `x_train` et `x_test` obtenus :\n",
    "- en ajoutant une quatrième dimension égale à 1 aux tableaux `im_train` et `im_test` \n",
    "- et en normalisant les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_train.shape, x_train.shape, im_test.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise au format *one-hot* des labels MNIST\n",
    "\n",
    "Il faut mettre les labels MNIST au format *one-hot* qui permet de calculer l'erreur entre un label et la sortie de la couche de classification du réseau (voir le notebook `TP1_MNIST_dense.ipynb` pour les détails sur le format *one-hot*).<br>\n",
    "Consulter la page [tf.keras.utils.to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) sur la fonction `to_categorical` et en déduire comment transformer les tableaux `lab_train` et `lab_test` en tableaux `y_train` et `y_test` contenant des vecteurs encodés *hot-one* :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Construction du réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant construire dans la cellule ci-dessous le réseau de neurones **convolutionnel** à l'aide du module **keras**.\n",
    "\n",
    "Comme dans le TP1, on crée un objet `model` instance de la classe `Sequential` (cf [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)), puis on complète `model` de façon  incrémentale en ajoutant chaque couche avec la méthode `add` :\n",
    "\n",
    "- La couche d'entrée de type `InputLayer` (cf [tf.keras.layers.InputLayer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer)) sert à spécifier la forme des données d'entrée.<br>\n",
    "La forme attendue par keras pour des images en entrée est (height,widt,depth) : on pourra l'obtenir par exemple avec l'attribut `shape` de n'importe quelle image du tableau `x_train`.<br><br>\n",
    "\n",
    "- Les couches convolutionnelles sont de type `Conv2D` (cf [tf.keras.layers.Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)) :\n",
    "    - les 2 premiers arguments (positionnels) sont : \n",
    "        - le nombre de filtres de la couche\n",
    "        - la forme du filtre : on peut spécifier  `N` ou `(N,N)` pour spécifier un filtre N x N\n",
    "    - les autres arguments (nommés) utilisés sont :\n",
    "        - `stride` : le pas du déplacement du filtre de convolution, valeur par défaut :  `stride=1` (équivalent à `(1, 1)`))\n",
    "        - `padding=valid` : pas de padding, ou `padding=same` : sortie de même dimensions que l'entrée (défaut : `valid`)\n",
    "        - `activation` : choix de la fonction d'activation (`'relu'`, '`tanh'`...)<br><br>\n",
    "        \n",
    "- Les couches de *pooling* du réseau LeNet5 historique utilisent un filtre *average pool* qui correspond à la classe `AveragePooling2D`  (cf [tf.keras.layers.AveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D)), mais on aura de meilleurs résultats avec un filtrage *max pool* qui retient la valeur max des pixels dans la fenêtre du filtre (voir la page [tf.keras.layers.MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)). Principaux arguments à utiliser avec `MaxPool2D` :\n",
    "    - `pool_size` :  `N` ou `(N,N)` pour spécifier un filtre N x N (défaut : `(2,2)`)\n",
    "    - `strides` : int, tuple de 2 int, ou None. Si None (valeur par défaut), prend la même valeur que `pool_size`\n",
    "    - `padding` : comme pour la classe `Conv2D`<br><br>\n",
    "\n",
    "- Pour applatir les 16 *feature maps* 5x5 en un vecteur de 16 * 5 * 5 = 635 éléments, on peut utiliser une couche  `Flatten` (cf [tf.keras.layers.Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten))<br><br>\n",
    "\n",
    "En s'inspirant de la structure du réseau `LeNet5` et des spécification ci-dessus, on obtient :\n",
    "- couche d'entrée : `Input(shape=x_train[0].shape)` : on utilise l'attribut `shape` de la 1ère image qui vaut (28,28,1).\n",
    "- couche C1 : `Conv2D(6, 5, padding='same', activation='relu', name='C1')`\n",
    "- couche S2 : `MaxPool2D(pool_size=2, name='S2')`\n",
    "- couche C3 : `Conv2D(16, 5, padding='valid', activation='relu', name='C3')`\n",
    "- couche S4 : `MaxPool2D(pool_size=2, name='S4')`\n",
    "- couche d'applissement : `Flatten()`\n",
    "- couche C5 : `Dense(200, activation='relu', name='C5')`\n",
    "- couche F5 : `Dense(84, activation='relu', name='F6'`\n",
    "- couche OUTPUT : `Dense(nb_classe, activation='softmax', name='Output')`\n",
    "\n",
    "Une fois construit, le réseau doit être compilé (au sens de tensorflow) avec la méthode `compile` en utilisant par exemple les :\n",
    "- `loss='categorical_crossentropy'` : choix de la fonction d'erreur (cf [tf.keras.categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy))\n",
    "- `optimizer='adam'` : choix de l'optimiseur Adam (cf page [tf.keras.optimizers.Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam))\n",
    "- `metrics=['accuracy']` pour obtenir les données permettant de tracer les courbes de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "nb_classe = 10\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "model = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la méthode `summary` de l'objet `model`, faire afficher la description du modèle : noter les valeurs des paramètres..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `tf.keras.utils.plot_model` permet aussi de dessiner la structure du réseau (voir la page [tf.keras.utils.plot_model](https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model)).<br>\n",
    "Faire tracer la structure du modèle en ajoutant l'option `show_shapes=True` à l'appel de `model` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde de l'état initial du  réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut sauvegarder l'état initial des poids du réseau non-entraîné (valeurs aléatoires) avec la méthode `Model.save_weights`. <br>\n",
    "Ce sera utile plus loin pour remettre le réseau à son état initial avant de relancer d'autres entraînements :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# vérifier que le dossier 'weights' existe et sinon le créer:\n",
    "if not os.path.exists(\"weights\"): os.mkdir(\"weights\")\n",
    "\n",
    "# sauvegarde des poinds du réseau initial:\n",
    "key = 'conv_initial'\n",
    "model.save_weights('weights/'+key)\n",
    "\n",
    "# afficher les fichiers créés:\n",
    "files=[os.path.join(\"weights\",f) for f in os.listdir(\"weights\") if f.startswith(key)]\n",
    "for f in files: print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : la méthode `save_weights` utilise la partie `key` du chemin passé en argument pour préfixer les fichiers créés.<br>\n",
    "Lors de la lecture ultérieure des poids du réseau avec la méthode `load_weights` de la classe `Sequential`, il suffira de donner la même information pour retrouver les bons fichiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Entraînement du réseau avec test à chaque `epoch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulter au besoin la documentation de la méthode `fit` dans la page [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). \n",
    "\n",
    "Compléter la cellule ci-dessous pour entraîner le réseau en utilisant la méthode `fit` de l'objet `model` avec les arguments :\n",
    "- `x_train` : les 60000 images \n",
    "- `y_train` : les 60000 labels encodés *one-hot*.\n",
    "- `epochs=10` : faire 10 fois l'entraînement complet.\n",
    "- `batch_size=64` : découper le jeu des données d'entrée (les 60000 images) en \"lots\" (*batch*) de taille `batch_size`.<br>\n",
    "La mise à jour des poids du réseau est faite au bout de `batch_size` échantillons d'entrée. La valeur de `batch_size` (par défaut est 32) est un paramètre qui influe beaucoup sur la qualité de l'apprentissage : on peut essayer d'autres valeurs (64, 128 ...) et observer comment évoluent les performances d'entraînement).\n",
    "\n",
    "Pour avoir un indicateur réaliste de la qualité du réseau entraîné on teste à chaque `epoch` la précison du réseau entraîné en utilisant les données de test : il faut passer l'agument `validation_data` à la méthode `fit`, en lui affectant le tuple des données de test `(x_test, y_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# au cas on on exécute plusieurs fois cette cellule, il faut ré-initialiser \n",
    "# les poids du réseau à leur valeur initiale si on veut comparer les entraînements...\n",
    "key = 'conv_initial'\n",
    "model.load_weights('weights/'+key)  \n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "hist = model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet `hist` retourné par la méthode `fit` possède un attribut `history` de type dictionnaire dont les clefs `'loss'`, `'accuracy'` contiennent l'évaluation de la fonction de cout et de la précision du réseau à la fin de chaque (*epoch*) avec les données d'entraînement. Les clefs `'val_loss'` et `'val_accuracy'` sont associées aux données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])\n",
    "print(hist.history['val_loss'])\n",
    "print(hist.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracé des courbes `accuracy` et `loss`  de l'entraînement et des test :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `plot_loss_accuracy` du module `utils.tools` (présent dans le répertoire du notebook) permet de tracer les courbes de précision et de perte en utilisant les données stockées dans l'objet `hist`. Faire tracer ces courbes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrêter automatiquement l'entraînement avant *over-fit*\n",
    "\n",
    "Keras propose des outils pour arrêter automatiquement l'apprentissage en surveillant par exemple la croissance de `val_accuracy` ou la décroisance de `val_losss` d'une `epoch` à l'autre (cf le callback  [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)).\n",
    "\n",
    "On peut ainsi définir une liste de fonctions *callback* que l'on peut passer en argument à la fonction `fit` avec l'agument nommé  `callbacks` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "callbacks_list = [\n",
    "    EarlyStopping(monitor='val_loss',  # la grandeur à surveiller\n",
    "                  patience=2,              # on accepte que 'val_accuracy' puisse diminuer 2 fois de suite\n",
    "                  restore_best_weights=True,\n",
    "                  verbose=1)\n",
    "]\n",
    "\n",
    "# recharger l'état initial du réseau:\n",
    "key = 'conv_initial'\n",
    "model.load_weights('weights/'+key)  \n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=15, \n",
    "                    batch_size=12, \n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracer les courbes `loss` et `accuracy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import plot_loss_accuracy\n",
    "plot_loss_accuracy(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le réseau convolutionnel tend vers une meilleure précision voisine de 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder les poids du  réseau entraîné"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `save_weights` de la classe `Sequential`permet d'enregistrer les **poids** du réseau entraïné dans un fichier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# vérifier que le dossier 'weights' existe et sinon le créer:\n",
    "if not os.path.exists(\"weights\"): os.mkdir(\"weights\")\n",
    "\n",
    "# sauvegarde des poids du réseau entrainé:\n",
    "key = 'conv_trained'\n",
    "model.save_weights('weights/'+key)\n",
    "\n",
    "# afficher les fichiers créés:\n",
    "files=[os.path.join(\"weights\",f) for f in os.listdir(\"weights\") if f.startswith(key)]\n",
    "for f in files: print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder la structure du réseau et ses poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `save` de la classe `Sequential` permet d'enregistrer **toute la structure et les poids** du réseau entraïné dans un fichier.<br />\n",
    "Ceci permet de recréer plus tard *from scratch* le réseau entrainé pour passer en phase exploitation du réseau par exemple, en utilisant la fonction`tf.keras.models.load_model` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# vérifier que le dossier 'weights' existe et sinon le créer:\n",
    "if not os.path.exists(\"models\"): os.mkdir(\"models\")\n",
    "\n",
    "# sauvegarder structure réseau + poids :\n",
    "key = 'conv_trained'\n",
    "model.save('models/'+key) \n",
    "\n",
    "# afficher les fichiers créés:\n",
    "files=[os.path.join(\"models\",f) for f in os.listdir(\"models\") if f.startswith(key)]\n",
    "for f in files: print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6/ Exploitation du réseau avec le jeu de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `predict` de l'objet `model` permet de calculer les inférences du réseau pour une ou plusieurs entrées (voir la méthode `predict`dans la page [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)).\n",
    "\n",
    "La cellule ci-dessous montre la mise en oeuvre de la méthode `predict`, et comment exploiter la représentation  *one-hot* renvoyée par `fit` en utilisant la méthode `argmax` des tableaux de numpy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import plot_images\n",
    "\n",
    "i = 100   # numéro image de test\n",
    "rep = model.predict(x_test[i:i+1]) # Attention: x doit être un tableau de matrices...\n",
    "                                   # => x[i] ne convient pas !\n",
    "\n",
    "print(f\"sortie du réseau pour l'image de rang {i} :\\n{rep[0]}\")\n",
    "\n",
    "# limiter l'affichage des composantes des tableaux numpy à 1 chiffre :    \n",
    "with np.printoptions(formatter={'float':'{:.2f}'.format}):    \n",
    "    print(f\"\\nsortie réseau arrondie à 2 chiffre : {rep[0]}\")\n",
    "    \n",
    "print(f\"rep[0].argmax() donne : {rep[0].argmax()}\")\n",
    "\n",
    "print(f\"\\nLa bonne réponse est {lab_test[i]} soit en 'one-hot' : {y_test[i]}\")\n",
    "\n",
    "plot_images(im_test,i,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilité de la méthode numpy `ndarray.argmax` pour décoder le tableau de vecteurs *one-hot* renvoyé par la méthode `predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand on calcule l'inférence du réseau `model` avec les données de test par exemple, on obtient un résultat qui est un tableau de vecteurs codés *one-hot*, comme le détaille la cellue suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(x_test)\n",
    "\n",
    "print(\"forme du tableau 'results':\", results.shape)\n",
    "print(\"allure des vecteurs du tableau 'result', par exemple :\")\n",
    "with np.printoptions(formatter={'float':'{:.4f}'.format}): \n",
    "    print(\"results[0]  :\", results[0])\n",
    "    print(\"results[-1] :\", results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En écrivant `results.argmax(axe=-1)`, on obtient le tableau des `argmax` de chaque vecteur -> c'est directement le tableau des chiffres reconnus par le réseau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiffres_reconnus = results.argmax(axis=-1)\n",
    "\n",
    "print(\"chiffres_reconnus -> shape:\", chiffres_reconnus.shape, \", dtype:\", chiffres_reconnus.dtype)\n",
    "print(f\"contenu de chiffres_reconnus : {chiffres_reconnus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrouver le taux de réussite du réseau entrainé en utilisant les inférences du réseau pour les entrées `x_test` et les labels `lab_test` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(x_test)\n",
    "chiffres_reconnus = results.argmax(axis=-1)\n",
    "\n",
    "success = 0\n",
    "for chiffre, label in zip(chiffres_reconnus, lab_test):\n",
    "    success += (chiffre == label)\n",
    "print(f\"taux de réussite : {success/len(x_test)*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Afficher la matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante définie la fonction `show_cm_mnist` qui affiche la **matrice de confusion**.\n",
    "\n",
    "La matrice de confusion permet de visualiser :\n",
    "- sur la diagonale : les bonnes réponses du réseau, avec dans chaque case le nombre de bonnes réponses\n",
    "- hors diagonale : les erreurs du réseau, avec dans chaque case la fréquence d'apparition de l'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def show_cm_mnist(target, results, classes):\n",
    "    # target  : the actual labels (one-hot format)\n",
    "    # results : the labels computed by the trained network (one-hot format)\n",
    "    # classes : list of possible label values\n",
    "    predicted = np.argmax(results, axis=-1) # tableau d'entiers entre 0 et 9 \n",
    "    cm = confusion_matrix(target, predicted)\n",
    "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    plt.figure(figsize=(11,9))\n",
    "    heatmap(df_cm, annot=True, cbar=False, fmt=\"3d\")\n",
    "    plt.xlabel('actual label')\n",
    "    plt.ylabel('predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire afficher la matrice de confusion en lui passant les labels attendus `lab_test` et les labels calculés par le model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectivement, il y a assez peu d'erreurs hors diagonale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D/ Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire reconnaître des images originales à un réseau entraîné avec les images MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs possibilités :\n",
    "- utiliser des images crées pour l'occasion... \n",
    "- utiliser les images toutes prêtes du répertoire `chiffres`.\n",
    "\n",
    "Si tu crées tes propres images de chiffres écrits à la main, il faut :\n",
    "- les mettre au format MNIST (20x28 pixels en ton de gris, chiffre centré dans l'image) \n",
    "- les placer dans un répertoire spécifique ,\n",
    "- affecter ce nom de ce répertoire à `images_dir` dans la cellule ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# changer le nom du répertoire au besoin :\n",
    "images_dir = \"chiffres\"\n",
    "\n",
    "images = [os.path.join(images_dir,f) for f in os.listdir(images_dir) if f.endswith(\".png\")]\n",
    "images.sort()\n",
    "\n",
    "print(f\"Images du dossier <{images_dir}> à reconnaître :\")\n",
    "for im in images: print(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des fichiers image avec openCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les images doivent être convertie en image en ton de gris de 28 x 28 pixels pour pouvoir être traitées par le réseau entraîné sur les images MNIST.\n",
    "\n",
    "Plusieurs fonctions du module OpenCV pourront être utilisées :\n",
    "- `cv2.imread(file_name)` : pour lire un fichier image aux formats standards (PNG, JPG,...)\n",
    "- `cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)` : pour convertir le tableau `img` renvoyé par `cv2.imread` en tons de gris\n",
    "- `cv2.resize` : pour retailler l'image.\n",
    "\n",
    "La cellule ci-dessous montre un exemple de lecture et traitement avec OpenCV des images du dossier `chiffres` qui sont déjà au format 28 x 28 pixe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_images = []\n",
    "for image_path in images:\n",
    "    img = cv2.imread(image_path)                    # lecture fichier image\n",
    "    img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # conversion en tons de gris\n",
    "    my_images.append(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des images lues :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(my_images, 0, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inversion des images pour avoir des chiffres doivent être en blanc sur fond noir :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_images = [255 - im for im in my_images]\n",
    "plot_images(my_images, 0, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant :\n",
    "- transformer des matrices 28x28 en tableaux (28,28,1) de float normalisés,\n",
    "- calculer les inférences du réseau entaîné de votre choix (`model` ou autre...) avec les images perso en entrée,\n",
    "- faire afficher la précision obtenue et la matric de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que suggèrent les  résultats ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autres ressources intéressantes... des vidéos :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/trWrEWfhTVg\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/trWrEWfhTVg\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/aircAruvnKk\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/aircAruvnKk\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
